# 提高C++性能的编程技术

# 跟踪实例

**要点：**

- **对象定义会触发隐形执行构造函数和析构函数。**我们称其为“隐形执行”而不是“隐形开销”，是因为对象的构造和销毁并不总是意味着产生开销。如果构造函数和析构函数所执行的计算是必须的，那么就要考虑使用高效的代码（内联会减少函数调用和返回的开销）。就像我们所看到的那样，构造函数和析构函数并不是总是具有如此 “完美的“ 特性， 而且它们能够产生可观的开销。某些情况下，构造函数（或析构函数） 所执行的计算是无用的。我们还应当指出， 这个问题不止是一个 C++ 语言编程的问题，更是一个设计问题。 不过，因为 C 不支持构造函数和析构函数， 所以这种现象在 C 中比较少见。

- 正是因为通过引用传递对象还是不能保证良好的性能，所以避免对象的复制的确有利于提高性能，但是如果我们不必一开始就创建和销毁该对象的话，这种处理方式将更有利于性能的提升。
- **不要把精力浪费在计算结果根本不会被使用的地方。**当关闭跟踪时，string 成员的创建就是一种无用而高代价的开销。
- **别打算创造设计灵活性的世界纪录。**您的设计只需要在当前问题范围之内足够灵活就可以了。在完成同样的简单工作时，char 指针有时可以比 string 对象更有效率。
- **内联消除了常被使用的小函数调用所产生的函数开销。** 内联 Trace 的构造函数和析构函数使得消除 Trace 的开销变得更加容易。



# 构造函数和析构函数

**要点：**

- 构造函数和析构函数可以像手工编写的 C 代码一样有效。然而在实践中，它们经常包含冗余计算。
- **对象的创建（或销毁）触发对父对象和成员对象的递归创建（或销毁）**。要当心复杂层次中对象的复合使用。 它们使得创建和销毁的开销更为高昂。
- **要确保所编写的代码实际使用了所有创建的对象和这些对象所执行的计算。**我们鼓励程序员深入研究他们所使用的类。这个建议不会受到面向对象程序设计提倡者的欢迎，毕竟面向对象的程序设计劝诫将类作为黑盒使用，不鼓励人们窥探其内部结构。怎样平衡这两条相互对立的建议呢？这个问题没有简单的答案， 因为它与所处的环境有关。尽管黑盒方法对千80%的代码都能表现得十分完美， 但它却可能对另外20%性能要求苛刻的代码造成很大 的伤害。它也是与应用程序相关的。有的应用程序注重可维护性和灵活性， 而另一些应用程序则可能把对性能的考虑放在最为重要的位置。 作为程序员， 应当清楚自已到底更看重哪个方面。
- 对象的生命周期不是无偿的。至少对象的创建和销毁会消耗 CPU 周期。不要随意创建一个对象，除非你打算使用它。通常情况下，**要等到需要使用对象的地方再创建它**。
- **编译器必须初始化被包含的成员对象之后再执行构造函数体。您必须在初始化阶段完成成员对象的创建。这可以降低随后在构造函数部分调用赋值操作符的开销。在某些情况下，这样也可以避免临时对象的产生。**



# 虚函数

**要点：**

- **虚函数的代价在于无法内联函数调用， 因为这些调用是在运行时动态绑定的。 唯一潜在的效率问题是从内联获得的速度（如果可以内联的话）。 但对于那些代价并非取决于调用和返回开销的函数来说， 内联效率不是问题。**
- **模板比继承提供更好的性能。它把对类型的解析提前到编译期间，我们认为这是没有成本的。**



# 返回值优化

**要点：**

- 如果必须按值返回对象，通过 RVO 可以省去创建和销毁局部对象的步骤，从而改善性能。
- RVO 的应用要遵照编译器的实现而定。这需要参考编译器文档或通过实验来判断是否使用 RVO 以及何时使用。
- 通过编写计算性构造函数可以更好地使用 RVO。

返回值优化（Return Value Optimization，RVO）



# 临时对象

**要点：**

- 临时对象会以构造函数和析构函数的形式降低一半的性能。
- 将构造函数声明为 **explicit**，可以阻止编译器在幕后使用类型转换。
- 编译器常常创建临时对象来解决**类型不匹配**问题。通过函数重载可以避免这种情况。
- 如果可能，应尽量避免使用对象拷贝。**按引用传递和返回对象**。
- 在 \<op> 可能是 “+、-、*” 或者 “/” 的地方，**使用 \<op>= 运算符可以消除临时对象**。



# 单线程内存池

**要点：**

- 灵活性以速度的降低为代价。随着内存管理的功能和灵活性的增强，执行速度将降低。

- 全局内存管理器（由 new() 和 delete() 执行）是通用的， 因此代价高。

- 专用内存管理器比全局内存管理器快一个数量级以上。
- 如果主要分配固定大小的内存块，专用的固定大小内存管理器将明显地提升性能。
- 如果主要分配限于单线程的内存块， 那么内存管理器也会有类似的性能提高。 由于省去了全局函数 new() 和 delete() 必须处理的并发问题， 单线程内存管理器的性能有所提高。



# 多线程内存池

**要点：**

- 全局内存管理器（通过 new() 和 delete() 实现） 是通用的， 因此它的开销也非常大。

- 因为单线程内存管理器要比多线程内存管理器快得多，所以如果要分配的大多数内存块限于单线程中使用， 那么可以显著提升性能。
- 如果开发了一套有效的单线程分配器，那么通过模板可以方便地将它们扩展到多线程环境中。



# 内联基础

**要点：**

- 内联就是用方法的代码来替换对方法的调用。
- 内联通过消除调用开销来提升性能， 并且允许进行调用间优化。
- 内联的主要作用是对运行时间进行优化，当然它也可以使可执行映像变得更小。



# 内联——站在性能的角度

**要点：**

- 直接量参数与内联结合使用，为编译器性能的大幅提升开辟了更为广阔的空间。
- 使用内联有时会适得其反，尤其是滥用的情况下。内联可能会使代码量变大，而代码量增多后会较原先出现更多的缓存失败和页面错误。
- 非精简方法的内联决策应根据样本执行的配置文件来制定，不能主观胧断。
- 对于那些调用频率高的方法，如果其静态尺寸较大，而动态尺寸较小，可以考虑将其重写， 从而抽取其核心的动态特性， 并将动态组件内联。
- 精简化与唯一化方法总是可以被内联。



# 内联技巧

**要点：**

- 内联可以改善性能。目标是找到程序的快速路径，然后内联它，尽管内联这个路径可能要费点工夫。
- 条件内联可以阻止内联的发生。这样就减少了编译时间，同时也简化了开发前期的调试工作。
- 选择性内联是种只在某些地方内联方法的技术。在对方法进行内联时，为了抵消可能的代码尺寸膨胀的影响，选择性内联只在对性能有重大影响的路径上对方法调用进行内联。
- 递归内联是一种让人感觉别扭，但对于改善递归方法性能却很有效的技术。

- 需要关注局部静态变量。
- 内联的目标是消除调用开销。在使用内联之前请弄清您系统中真正的调用代价。



# 标准模板库

**要点：**

- STL 是抽象、灵活性和效率的一种罕见的结合。
- 对于某种特定的应用模式，一些容器比其他的更加高效，这都要随着实际应用而定。

- 除非了解一些相关领域内 STL 所忽略的问题，否则您是不可能超过 STL 实现的。
- 不过，在一些特定的情况下，还是有可能超越 STL 实现的性能的。



# 引用计数

**要点：**

引用计数在性能上并非无往不胜。引用计数、执行时间和资源维护会产生微妙的相互作用，如果对性能方面的考虑很重要，就必须对这儿个方面仔细进行评估。引用计数是提升还是损害性能取决于其使用方式。下面的任意一种情况都可以使引用计数变得更为有效：

- 目标对象是很大的资源消费者。
- 资源分配和释放的代价很高。
- 高度共享；由千使用赋值操作符和拷贝构造函数，引用计数的性能可能会很高。
- 创建和销毁引用的代价低廉。

反之，则应跳出引用计数而转为使用更加有效的简单非计数对象。



# 编码优化

**要点：**

最快的代码是从不执行的代码。 请试着按照以下步骤去剔除那些代价高昂的计算：

- 您打算使用该计算结果吗？听起来有点可笑，但这种可笑的事确实会发生——有时我们执行了计算但从未使用计算的结果。
- 您现在需要该结果吗？请在真正需要的时候再进行计算。在一些执行流程中有些结果永远不会被使用， 因此不必过早地计算。
- 您是否已经知道结果？我们曾经见过程序中执行的许多代价高昂的计算，其结果在两行代码前就已经知道。如果在程序执行流程的前期已经计算出了结果， 那么应该使该结果成为可重用的。

有的时候可能无法绕开该计算，此时就必须完成它。那么现在的挑战就是加快计算速度：

- 该计算是否过于通用？您的实现只需要跟该领域要求的一样灵活就行，而无须奢求。 可以充分利用简化的假设以降低灵活性来增加速度。
- 一些灵活性隐藏在库的函数调用中。通过实现库调用的自定义版本可以提升速度。不过，这些库调用必须是被频繁调用的，否则您的努力将得不到明显效果。 熟悉您所使用的库和系统调用中隐藏的代价。

- 尽量减少内存管理调用的数量。在绝大多数编译器中，这些调用的代价都是非常高的。
- 如果考虑所有可能的输入数据， 则可以发现 20% 的数据在 80% 时间里出现。因此， 应当以牺牲其他不经常出现的场景为代价来提高典型输入的处理速度。
- 缓存、RAM 和磁盘访问的速度差异很明显。 应该多编写缓存友好的代码。



# 设计优化

**要点：**

- 在**软件性能和灵活性**之间存在一种基本的平衡。对于在 80% 时间内执行的 20% 的软件，性能通常损失在灵活性上。
- 在代码细节中可以利用**缓存**优化代码，在整个程序设计中也能采用这种方法。通常可以通过将先前的计算结果保存起来避免大量的计算。
- 对于软件的高效性而言，使用高效的**算法和数据结构**是必要条件，但并非充分条件。
- 有些计算只有在特定执行条件下才需要。这些计算应该被**推迟**到确实需要它们的路径上来完成。如果过早地执行计算，那么其结果可能并没有被使用。
- 大型软件往往会变得错综复杂，杂乱不堪。混乱软件的一大特点就是执行失效代码：那些曾经用来实现某个目标，但现在已经不需要的代码。**定期清理失效和僵死代码可以增强软件性能**，同时对于软件也是一种维护。



# 可扩展性

**要点：**

- SMP 是当前主流的多处理器架构。它通过一条总线连接多个对称的处理器和一个内存系统。总线是 SMP 架构可扩展性的薄弱环节。让每个处理器都有自己的大缓存可以有效地控制总线的竞争。
- Amdahl定律给出了一个应用的可扩展性的上限，顺序化计算限制了扩展性。

实现可扩展性的技巧是减少或者消除顺序化的代码。以下是可以达到这个目标的一些步骤：

- **任务分解** 将大的任务分为小任务，使线程并发地执行这些小任务。
- **代码移出** 临界区应该只包含关键代码，不直接操作共享资源的代码不要放在临界区内。
- **利用缓存** 有时，通过缓存之前访问过的数据，可以消除对临界区的访问。 
- **无共享** 如果需要少量、数目固定的资源实例，可以不使用公共资源池。您可以把这些资源实例设为线程私有，并最后回收。
- **部分共享** 有两个一样的资源池可以减少一半的竞争。
- **锁粒度** 不要用同样的锁来保护所有资源，除非这些资源是同时更新的。
- **伪共享** 不要在类定义里把两个使用频度都很高的锁放太靠近。您肯定不希望它们共享同一个缓存行并触发缓存一致性风暴。
- **惊群现象** 仔细分析您的锁调用的特征。当锁被释放时，是所有的等待线程都被唤醒还是只唤醒一个线程？唤醒所有线程会威胁到应用的可扩展性。
- **系统和类库调用** 考察这些调用的实现特征。它们有可能是隐藏了顺序化的代码。
- **读／写锁** 以读为主的共享数据会从这种锁中获益，使用这种锁，可以消除读者线程之间的竞争。



# 系统体系结构相关话题

**要点：**

- 要使用的存储器离处理器越远，访问所需的时间就越长。离处理器最近的是寄存器，虽然容量很少，但是速度很快。对寄存器的优化对程序的性能提升而言是极为有益的。
- 虚拟存储器并不是无偿的，不加选择地依赖系统管理的虚拟结构可能会影响性能，而且一般都是降低性能。
- 上下文切换的开销巨大，请避免上下文切换。
- 最后，虽然我们知道内部管理异步 I/O 有它的重要作用，我们还是认为正在到来的处理器架构的变化，会使得单个线程方法在这方面的优势减弱。
